---
title: "descriptive_stats"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{descriptive_stats}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```

```{r setup}
suppressPackageStartupMessages(library(MultiOmics4ImmunAID))
load_libraries(
    c(
        "corrplot",
        # "datawizard",
        "DataExplorer",
        "dlookr",
        "ggpubr",
        "ggstatsplot",
        "janitor",
        "lubridate",
        "magrittr",
        "naniar",
        "rstatix",
        "readxl",
        "reshape2",
        "see",
        "skimr",
        "tidyverse",
        "VIM"
    )
)
path <- file.path(golem::get_golem_wd(), "inst", "extdata")
```

# Proteomics

## ELISA

```{r elisa}
# prot_path <- file.path(path, "ELISA/Batch1")
batch <- 1
date <- "20211116"
prefix <- paste(date, "Data", "", sep = "_")
blocks <- c("Calprotectin", "S100A12")
files_raw <- list()

# Read files
for (i in seq_along(blocks)) {
    files_raw[[i]] <- read_excel(
        file.path(
            path,
            "ELISA/Batch1",
            paste0(prefix, blocks[i], "_batch_", batch, ".xlsx")
        ),
        skip = 5
    )
}
# Clean colnames, remove empty rows, cols and constants
files <- lapply(files_raw, clean_data)
# Common IDs ?
setdiff(files[[1]][, 1], files[[2]][, 1]) # character(0) = Nope !
# Bind tables
elisa <- cbind(files[[1]], files[[2]][, 4, drop = FALSE]) %>% tibble()
colnames(elisa)[4:5] <- blocks

# Set constants into the attributes
for (i in 4:5) {
    var <- colnames(files_raw[[1]])[i]
    attributes(elisa)[var] <- unique(files_raw[[1]][, var])
}

# Convert into types
str(elisa)
elisa$patient_id <- as.character(elisa$patient_id)
elisa$visit <- factor(elisa$visit)

# View factor
diagnose_category(
    elisa[, -c(1:2)],
    top = 500
)
# %>% filter(is.na(levels))
# %>% filter(ratio <= 0.01)

# elisa %>% count(visit)  %>% mutate(freq = n / sum(n))
# elisa %>% count(patient_id, sort = TRUE)  %>% mutate(freq = n / sum(n))

diagnose_numeric(elisa) # %>% filter(minus > 0 | zero > 0)
# View duplicates
elisa %>% get_dupes("patient_id")

# Descriptive stats general
plot_str(elisa)
introduce(elisa)
plot_intro(elisa)
diagnose(elisa) %>%
    filter(missing_count > 0) %>%
    arrange(desc(missing_count))

# Descriptive stats per variables
# qplot(Calprotectin, data = elisa)
plot_bar(elisa)
plot_histogram(elisa)
# plot_boxplot(elisa)
skim(elisa)
plot_violin(elisa)

# str_squish

# Correlation
plot_correlation(elisa)
# continuous data
plot_correlation(elisa, type = "c")
get_correlation(elisa)
plot_correlate(elisa)

# Normality
plot_qq(elisa)
# Do not follow the normality with Shapiro-Wilk
plot_normal(elisa)


# Missing data
# set_missing
plot_missing(elisa)
find_na(elisa)
# impute_na(elisa)

# Outliers
# find_outliers(elisa) # wich variables
diagnose_outlier(elisa) %>% filter(outliers_ratio > 0)
plot_outlier(elisa, typographic = FALSE)
elisa_w_out <- elisa
for (i in find_outliers(elisa)) {
    var <- colnames(elisa)[i]
    elisa_w_out[var] <- imputate_outlier(elisa, var, method = "mean")
}

# PCA
pca_df <- na.omit(elisa[, 4:5])
plot_prcomp(pca_df, nrow = 2, ncol = 2)

# eda_report(elisa)
```

# Clinic

```{r clinic}
# Extract items
date <- "20220512"
clin_path <- file.path(path, "clinical", "20220501")
files_raw <- list.files(clin_path)
files_code <- files_raw[grepl("codes", files_raw)]
files_export <- files_raw[grepl("export", files_raw)]
files <- str_split(files_export, "_")
(blocks <- unique(sapply(files, function(i) i[2])))
```

## Clinical

```{r clinical}
clin_export <- files_export[grepl("Clinical", files_export)]
clin_code <- files_code[grepl("Clinical", files_code)]
clinic <- read_batches()
sapply(clinic, dim)

clinic_tot <- Reduce(rbind, clinic)

clinic_code <- read_batches(, "codes")

# Common subject ID between batches
vars <- lapply(clinic, function(i) as.numeric(as.data.frame(i[, 2])[, 1]))
# vars <- lapply(clinic_code, function(i) as.data.frame(i[, 1])[, 1])
names(vars) <- seq(3)
plot_venn(vars)

get_intersection(vars)

# Common subject ID with ELISA
vars_clin <- sort(as.numeric(unlist(vars)))
vars_elisa <- sort(as.numeric(as.data.frame(elisa[, 2])[, 1]))
vars_tot <- list(Clinic = vars_clin, ELISA = vars_elisa)
vars_tot2 <- c(vars, list(ELISA = vars_elisa))
plot_venn(vars_tot)
# all included in clinic data
plot_venn(vars_tot2)
# all from clinic batch 1
get_intersection(vars_tot)

# Missing data
# set_missing
clinic_tot <- clean_data(clinic_tot, FALSE)
find_na(clinic_tot)

clinic_tot_proc <- best_na_percent(clinic_tot, 3)
plot_missing(
    clinic_tot_proc,
    geom_label_args = list(
        label.size = NA,
        label.padding = unit(0, "lines"),
        size = 3
    )
)

gg_miss_var(clinic_tot)
vis_miss(clinic_tot_proc)
clinic_code_proc <- clean_data(clinic_code[[1]])
# vis_miss(clinic_code_proc)
# vis_miss(best_na_percent(clinic_tot_proc, 0))
res <- summary(aggr(clinic_tot, sortVar = TRUE))$combinations
# impute_na(elisa)

# Categorical variables
# group_name
# The top bottom by frequency
diagnose_category(
    clinic_code_proc[, "group_name", drop = FALSE],
    top = 100
) %>% arrange(freq)
# Select the clinic data with 0 NA
var_na <- colnames(clinic_tot_proc)
# Look at the metadata in codes
(stats <- clinic_code_proc %>%
    filter(clinic_code_proc$column_code %in% var_na) %>%
    select(!(starts_with("repeat"))))

get_var_names(var_na, stats)

diagnose_category(as.data.frame(stats$group_name))
# Which is the frequence of this category
clinic_code_proc[, "group_name", drop = FALSE] %>%
    diagnose_category(top = 100) %>%
    filter(str_detect(levels, paste0(unique(stats$group_name), collapse = "|")))
# What are the most frequent modalities for each variable
plot_bar(clinic_tot_proc)
# Create country variable
clinic_tot_proc %>%
    mutate(
        country = case_when(
            str_detect(C_2643_3797, "Paris|Bordeaux|Nantes|Lyon|Lille|Strasbourg") ~ "France",
            str_detect(C_2643_3797, "Madrid|Barcelona") ~ "Spain",
            str_detect(C_2643_3797, "Leuven") ~ "Belgium",
            str_detect(C_2643_3797, "Rotterdam") ~ "Netherlands",
            str_detect(C_2643_3797, "Athens") ~ "Greece",
            str_detect(C_2643_3797, "Roma") ~ "Italy",
            str_detect(C_2643_3797, "Geneva") ~ "Switzerland",
            str_detect(C_2643_3797, "Ankara") ~ "Turkey",
            str_detect(C_2643_3797, "MÃ¼nster|Berlin") ~ "Germany",
            str_detect(C_2643_3797, "Leeds") ~ "United Kingdom (UK)",
            str_detect(C_2643_3797, "Lubljana") ~ "Slovenia",
            TRUE ~ C_2643_3797
        )
    ) %>%
    select(country) %>%
    plot_bar()

# By French centers
clinic_tot_proc %>%
    filter(str_detect(C_2643_3797, "Paris|Bordeaux|Nantes|Lyon|Lille|Strasbourg")) %>%
    select(C_2643_3797) %>%
    plot_bar()

# By French cities
clinic_tot_proc %>%
    mutate(
        town = case_when(
            str_detect(C_2643_3797, "Paris") ~ "Paris",
            str_detect(C_2643_3797, "Bordeaux") ~ "Bordeaux",
            str_detect(C_2643_3797, "Nantes") ~ "Nantes",
            str_detect(C_2643_3797, "Lyon") ~ "Lyon",
            str_detect(C_2643_3797, "Lille") ~ "Lille",
            str_detect(C_2643_3797, "Strasbourg") ~ "Strasbourg",
            TRUE ~ "Others"
        )
    ) %>%
    select(town) %>%
    plot_bar()

# %>% diagnose_category()

# Date
var_dates <- c("C_2643_3800", "C_2643_3801", "C_2643_3802")
clinic_tot_proc <- update_columns(clinic_tot_proc, var_dates[1], my)
clinic_tot_proc <- update_columns(clinic_tot_proc, var_dates[-1], dmy)
for (i in var_dates) {
    qplot(as.data.frame(clinic_tot_proc[, i])[, 1])
}

clin_proc_year <- update_columns(clinic_tot_proc, var_dates, function(i) year(round_date(i, "year")))
plot_histogram(clin_proc_year)

for (i in var_dates) {
    y <- as.data.frame(as.character(as.data.frame(clin_proc_year[, i])[, 1]))
    diagnose_category(y, top = 100) %>% arrange(freq)
}

# Age in decades
decade <- as.data.frame(as.character(as.data.frame(clin_proc_year[, "C_2643_3800"] - clin_proc_year[, "C_2643_3800"] %% 10)[, 1]))
diagnose_category(decade, top = 100) %>%
    arrange(levels) %>%
    select(-variables)
qplot(decade[, 1])
qplot(as.character(2020 - as.numeric(decade[, 1])))

# Correlation
# plot_correlate(clinic_tot_proc)
(p <- plot_corr(clinic_tot_proc, stats))
# save_tiff(p)

plot_corr(clinic_tot_proc, stats)
ggcorrmat(clinic_tot_proc)

# Stats / outliers
var_num <- get_name_num(clinic_tot_proc)

col_outliers <- explore_outliers(clinic_tot_proc)
i <- col_outliers[1] # "C_2643_3804"
j <- col_outliers[2] # "C_2649_3889"
clin_melt <- melt(clinic_tot_proc) %>% select(variable, value)
(clin_melt %>% filter(variable == i) %>% boxplot())$out
get_outliers(clinic_tot_proc, i)
# get_outliers(clinic_tot_proc, j, probs = c(.025, .975), method = "percentiles")
# get_outliers(clinic_tot_proc, j, , method = "hampel", c = 3)

plot_violin(clinic_tot_proc)
plot_violin2(clinic_tot_proc)
plot_violin3(clinic_tot_proc)
```

## PedsQL
```{r pedsql}
# Extract items
block <- "PedsQL"
peds_files <- files[grepl(block, files)]
batch <- unique(sapply(peds_files, function(i) { i[5] }))
max(gsub("batch(\\d)", "\\1", batch))
peds_files <- peds_files[grepl("batch1", peds_files)]
ql <- unique(sapply(peds_files, function(i) { i[2] }))
(ql <- sort(as.numeric(gsub("PedsQL(\\d+)", "\\1", ql))))
years <- unique(sapply(peds_files, function(i) { i[3] }))
(years <- sort(as.numeric(gsub("(\\d+)years", "\\1", years))))

# Load data
pql_blocks <- paste0(block, ql, "_", years, "years")
pql <- lapply(pql_blocks, read_batches)
# pql <- lapply(pql, function(i) lapply(i, function(j) clean_data(j, FALSE, FALSE)))
names(pql) <- pql_blocks
lapply(pql, function(i) sapply(i, dim))
# pql1 <- lapply(pql, function(i) sapply(i, colnames))[[4]]; plot_venn(lapply(seq(ncol(pql1)), function(i) pql1[, i]))

# Duplicate individuals between batches
lapply(pql, function(i) get_intersection(lapply(i, function(i) as.data.frame(i[, 1])[, 1])))
plot_venn(lapply(pql, function(i) colnames(i[[1]])))

# Metada
pql_codes <- lapply(pql_blocks, function(i) read_batches(i, "codes"))
colnames(pql_codes[[1]][[3]])
pql_names <- lapply(pql_codes, function(i) i[[3]]$item_name)
plot_venn(pql_names)
get_intersection(pql_names)
get_difference(pql_names)

# Select level variables
level_vars <- lapply(pql_codes, function(i) (i[[1]] %>% filter(!str_detect(item_name, paste0(c("ImmunAID identifier", "Form completed on:"), collapse = "|"))))$column_code)
level_ <- na.omit(sort(unique(unlist(mapply(function(x, y) select(x[[3]], all_of(y)), pql, level_vars)))))

# group_code
peds_regex <- "PedsQL(\\d{1,2})_(\\d{1,2})_"
group_codes <- pql_codes[[4]][[3]]$group_code
pql_groups <- unique(gsub(peds_regex, "", group_codes))
pql_groups0 <- unique(gsub("V\\d_", "", pql_groups))
sapply(pql_groups0, function(i) length(group_codes[str_detect(group_codes, i)]))

# item codes
pql_item_code <- lapply(pql_codes, function(i) gsub(peds_regex, "", i[[3]]$item_code))
plot_venn(pql_item_code)
# Compare item_name for each group_code between ages
get_intersection(pql_item_code)
# $`B:C:D` "SCHOOL_FUNCTIONING_4" "SCHOOL_FUNCTIONING_5"

# TODO: Reduce
pql_tot <- lapply(pql, function(i) Reduce(rbind, i))

# Duplicates individuals
get_dup_name(pql_tot[[3]])
get_dup(pql_tot[[3]])

for (i in seq_along(pql)) {
    colnames(pql_tot[[i]]) <- pql_item_code[i][[1]]
}

i_cols <- which(str_detect(pql_item_code[1][[1]], "SCHOOL_FUNCTIONING_1"))
# name_cols <- rep(paste0("SCHOOL_FUNCTIONING_", seq(2)), 2)
# Add SCHOOL_FUNCTIONING_[45] in 24 25 48 49 with NA
for (i in seq(2)) {
    pql_tot[[1]] <- add_column(pql_tot[[1]], SCHOOL_FUNCTIONING_4 = NA, SCHOOL_FUNCTIONING_5 = NA, .before = i_cols[i])
}
colnames(pql_tot[[1]]) <- colnames(pql_tot[[4]])
# Then add Date in 26 for i = {1, ,2, 3} with NA
i_col <- which(str_detect(pql_item_code[4][[1]], "DATE"))[2]
for (i in 2:3) {
    pql_tot[[i]] <- add_column(pql_tot[[i]], DATE = NA, .before = i_col)
}

pql_tot <- Reduce(rbind, pql_tot)
# sapply(as.data.frame(pql_tot)[, which(str_detect(pql_item_code[4][[1]], "SCHOOL_FUNCTIONING"))], unique)

for (i in 0:4) {
    pql_tot[pql_tot == level_[i + 1]] <- paste0(i)
}

pql_tot <- clean_data(pql_tot)
```

# SF36
```{r}
sf36 <- read_batches("SF36")
sapply(sf36, dim)

sf36_tot <- Reduce(rbind, sf36)

sf36_code <- read_batches("SF36", "codes")

# group_code
group_codes <- sf36_code[[1]]$group_code
sf36_groups <- unique(gsub("SF36_", "", group_codes))
sf36_groups0 <- unique(gsub("(V\\d_)|(_2)", "", sf36_groups))
sapply(sf36_groups0, function(i) length(group_codes[str_detect(group_codes, i)]))
```

## Session information
```{r end, echo = FALSE}
sessionInfo()
```
